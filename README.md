# pdf-voice-clone
AI pipeline that turns PDF text into speech, cloned in your own voice (XTTS v2 + Streamlit).
# xtts-voicebook
Convert any PDF into an **audiobook in your own cloned voice** using **Coqui XTTS v2** and a minimal **Streamlit** UI.

> Backend: `pdf_to_voice_clone_short.py`  
> UI: `streamlit_app.py` (calls the backend and handles uploads)

---

## âœ¨ Features
- Upload a **PDF** and a short **voice sample** (mp3/mp4/wav/m4a/aac/flac/ogg).
- Pick **start/end pages** in the UI (0-based, inclusive).
- XTTS v2 **clones your voice** and synthesizes the audiobook.
- Model is **cached once per process** â†’ faster repeat runs.
- Streamlit media is served from **session state** (robust across reruns).

---

## ğŸš€ Quick Start

### 0) Clone and enter the folder
```bash
git clone https://github.com/<YOUR_USERNAME>/xtts-voicebook.git
cd xtts-voicebook
1) Install Python deps
bash
Copy code
pip install -r requirements.txt
2) Install PyTorch properly (pick one)
CPU-only:

bash
Copy code
pip install --index-url https://download.pytorch.org/whl/cpu torch torchaudio
CUDA 12.1 (NVIDIA GPU):

bash
Copy code
pip install --index-url https://download.pytorch.org/whl/cu121 torch torchaudio
3) Install FFmpeg
Windows: download a static build from https://www.gyan.dev/ffmpeg/builds/ â†’ unzip â†’ add bin\ to PATH.

macOS (Homebrew): brew install ffmpeg

Ubuntu/Debian: sudo apt-get update && sudo apt-get install -y ffmpeg

4) Run the app
bash
Copy code
streamlit run streamlit_app.py
Open http://localhost:8501 and:

Upload a PDF

Upload your voice sample (5â€“30 seconds is enough)

Choose page range

Click Generate

ğŸ§© Repo Structure
bash
Copy code
.
â”œâ”€â”€ pdf_to_voice_clone_short.py   # Backend: PDF â†’ text â†’ XTTS â†’ audio
â”œâ”€â”€ streamlit_app.py              # Streamlit UI (uploads, page range, download)
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
âš™ï¸ How It Works (in brief)
pypdf extracts text from the selected pages.

Text is sentence-chunked (~280 chars) to keep XTTS happy.

Your voice sample is normalized to mono 16 kHz WAV for conditioning.

Coqui XTTS v2 synthesizes each chunk; pydub concatenates with brief silence.

Output is exported as MP3 (or WAV if you change the extension).

âš¡ Performance Tips
GPU strongly recommended for long books (install the matching CUDA wheel).

We cache the model using a global in the backend; subsequent runs are faster.

Increase MAX_CHARS to ~320 for fewer TTS calls (trade-off: slightly less pause control).

Reduce ADD_SIL_MS to shorten overall length between segments.

In the UI, use the â€œPreload voice modelâ€ sidebar button before generating.

ğŸ§ª File Formats & Limits
PDF must contain selectable text. If itâ€™s scanned images, run OCR first (e.g., OCRmyPDF).

Voice sample should be clean speech, minimal noise/reverb (5â€“30 s is ideal).

Supported voice formats: mp3, mp4, wav, m4a, aac, flac, ogg.

ğŸ› ï¸ Troubleshooting
Streamlit media error: MediaFileStorageError ... Missing file ...
This happens when Streamlit reruns and the file ID vanishes.
Fixed: the app stores audio bytes in st.session_state and uses a stable temp dir. If you still hit it, ensure you didnâ€™t change the render to st.audio(<path>) (must use bytes).

Torchaudio dispatch warning
vbnet
Copy code
UserWarning: Torchaudio's I/O functions now support ...
Harmless. We silence it in the UI. If you want to fix at the source, pin matching torch/torchaudio versions (see install section).

â€œNo extractable text (OCR may be required)â€
Your PDF is likely scanned. Run OCR:

bash
Copy code
ocrmypdf input.pdf output.pdf
Use output.pdf in the app.

Slow first run
First run downloads the model and builds caches (normal). Use the sidebar preload button to warm the model before generating.

ğŸ” Privacy Notes
Your audio and generated segments are written to a temporary session directory.

Nothing is uploaded anywhere by default; everything runs locally.

Clear the session (Reset expander) to remove generated bytes from memory.

ğŸ“œ License
MIT â€” do anything, just keep the license.

ğŸ™ Credits
Coqui TTS / XTTS v2 for multilingual voice cloning.

Streamlit, PyPDF, pydub, NLTK for the glue.

css
Copy code

If you want a version with **screenshots** or a **Mermaid architecture diagram** section prefilled, 
